{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle\n",
    "\n",
    "#import xgbtune "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"../data/dataset.parquet\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = \"target_close\"\n",
    "target = \"close_percent_change_1\"\n",
    "\n",
    "x = df.drop(columns=[target]).set_index(\"date\")\n",
    "y = df[[\"date\", target]].set_index(\"date\")\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_info = pd.DataFrame()\n",
    "\n",
    "# Print columns that are not int, float, bool or category\n",
    "for col in x.columns:\n",
    "    dtype = x[col].dtype\n",
    "    if dtype not in [\"int\", \"float64\", \"bool\", \"category\"]:\n",
    "        table_info = pd.concat([table_info, pd.DataFrame({\"Column Name\": [col], \"Data Type\": [x[col].dtype]})])\n",
    "\n",
    "table_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert columns to float if they are not int, float, bool or category. Handle Cannot cast DatetimeArray to dtype float64 (XGBoosted models cannot use strings, but categories as enumerated values)\n",
    "for col in x.columns:\n",
    "    dtype = x[col].dtype\n",
    "    if dtype not in [\"int\", \"float64\", \"bool\", \"category\"]:\n",
    "        try:\n",
    "            x[col] = x[col].astype(\"float\")\n",
    "        except:\n",
    "            # drop datetime columns\n",
    "            x = x.drop(columns=[col])\n",
    "\n",
    "            print(f\"Dropped Column: {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Normalizing the features between 0 and 1\n",
    "# y_scaler = MinMaxScaler()\n",
    "# y = y_scaler.fit_transform(y.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# x_scaler = MinMaxScaler()\n",
    "# x = x_scaler.fit_transform(x)\n",
    "\n",
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    All Features   | Target\n",
    "# +-----------------+---------+\n",
    "# | x_train         | y_train | <- 85% of the data which is used for training\n",
    "# |                 |         |\n",
    "# +-----------------+---------+\n",
    "# | x_test          | y_test  | <- 15% of the data which is used for testing\n",
    "# +-----------------+---------+\n",
    "\n",
    "\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.15, shuffle=False)\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.5, shuffle=True)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, shuffle=True)\n",
    "# x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "from itertools import count, takewhile\n",
    "def frange(start, stop, step):\n",
    "    return takewhile(lambda x: x< stop, count(start, step))\n",
    "\n",
    "# list(frange(0, 1, 0.1))\n",
    "numpy.linspace(5, 10, num=6).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = xgb.XGBRegressor(n_estimators=100, max_depth=7, eta=0.1, subsample=1, colsample_bytree=.3)\n",
    "# model = xgb.XGBRegressor(n_estimators=150, max_depth=7, eta=0.05, subsample=1, colsample_bytree=.3)\n",
    "# model = xgb.XGBRegressor(n_estimators=100, max_depth=7, eta=0.05, subsample=1, colsampvle_bytree=.3)\n",
    "model = xgb.XGBRegressor(n_estimators=500, max_depth=7, eta=0.05, subsample=0.9, colsample_bytree=0.4)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import GridSearchCV, HalvingGridSearchCV, HalvingRandomSearchCV\n",
    "\n",
    "tune_params = {\n",
    "    # \"n_estimators\": [100, 150],\n",
    "    # \"max_depth\": [5, 6,],\n",
    "    # \"learning_rate\": [0.05, 0.1],\n",
    "\n",
    "    \"n_estimators\": [400, 450, 500, 550, 600],\n",
    "    \"max_depth\": [6, 7, 8, 9, 11],\n",
    "    \"learning_rate\": [0.05, 0.1, 0.2, 0.3, 0.4,],\n",
    "    \"subsample\": [0.7, 0.8, 0.9, 1.0, 1.1],\n",
    "    \"colsample_bytree\": [0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "\n",
    "}\n",
    "\n",
    "# {'subsample': 0.9, 'n_estimators': 500, 'max_depth': 7, 'learning_rate': 0.05, 'colsample_bytree': 0.3}\n",
    "# {'subsample': 0.8, 'n_estimators': 400, 'max_depth': 7, 'learning_rate': 0.05, 'colsample_bytree': 0.2}\n",
    "\n",
    "# xgb_model = xgb.XGBRegressor()\n",
    "# # model = GridSearchCV(estimator=xgb_model, param_grid=tune_params)\n",
    "# model = HalvingRandomSearchCV(estimator=xgb_model, param_distributions=tune_params)\n",
    "# model.fit(x_train, y_train)\n",
    "\n",
    "# print(model.best_params_)\n",
    "\n",
    "pickle.dump(model, open(\"../model/xgboost_model.pkl\", \"wb\")) # Save model as Python pickle object\n",
    "model.save_model(\"../model/xgboost_model.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model.best_params_)\n",
    "# model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model.predict(x_test)\n",
    "y_test[\"predicted\"] = predicted\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the root mean squared error (RMSE)\n",
    "mse = np.mean((y_test[\"predicted\"] - y_test[target]) ** 2)\n",
    "rmse = np.sqrt(mse)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the mean absolute error (MAE)\n",
    "mae = np.mean(np.abs(y_test[\"predicted\"] - y_test[target]))\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.01455269590461311\n",
    "# 0.013673832772506729\n",
    "# 0.012685448862479572"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rmsle\n",
    "rmsle = np.sqrt(np.mean(np.log1p(np.abs(y_test[\"predicted\"] - y_test[target])) ** 2))\n",
    "rmsle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the mean absolute percentage error (MAPE)\n",
    "mape = np.mean(np.abs((y_test[target] - y_test[\"predicted\"]) / y_test[target])) * 100\n",
    "mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predicted values\n",
    "y_test.sort_index().to_parquet(\"../data/predicted.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
